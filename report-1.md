# Report 1

The goal of this research is to develop a tool that generates high level representations or visualizations of malware, to facilitate an analyst or automated tool's initial understanding of some function or the malware as a whole. The problem this tool will help solve, is that when reversing malware an analyst might spend a considerable amount of time digging into the disassembly of some function to figure out that it, for example, waits until it receves some file from the network, and writes it to disk. The tool will attempt to visualize the malware in a way that the key side effects of some functoin are instantly recognizable. As this research has evolved, however, the scope has expanded somewhat, as I'll explain later. 

As per the agreed upon schedule, the half of this study focuses on designing and developing the backend analyses. To accomplish this I have implemented a "tagging system", which appends a specification of the semantics for any supported instruction, function, binary, etc. The semantics at each tag are expressed using a custom domain specific language (DSL), which is capable of representing those side effects most often relevant to malware behavior. 

This DSL (which is quite rudimentary at this stage), is essentially a dialect of LISP. Its purpose is not to be executed, but rather to represent what some part of the program does in a simplified way. Instructions are specified in all caps (for example `WRITE`, `READ`, etc), and data types are all lowercase (for example `host`, `memory`, etc). When the language wants to include raw data from the program, it is represented using a string (for example "192.168.1.100"). 

Currently it only supports a few basic operations. Here is a simple example of a potential tag. 

```
(WRITE <src> <destination>)
(READ <src> <destination>)
(MOVE <src> <destination>)
```

This DSL then has a series of "optimization" passes. However, unlike most optimizers, the goal of these are not speed, but rather rewriting, simplifying and lifting representations. For example, a sequence of statements like

```
(READ (file "/etc/shadow"), (memory "var1"))
(WRITE (memory "var1"), (host "192.168.1.100"))
```

will first be simplified to

```
(WRITE (file "/etc/shadow"), (host "192.168.1.100"))
```

then (in a second pass), be lifted to

```
(SEND (file "/etc/shadow"), (host "192.168.1.100"))
```

After the tagging, optimization, and lifting loop, each function should be tagged with its semantics expressed in this DSL. There are then various options for how to use this representation for malware analysis. 

 - Pass that lifts beyond function level, saying SEND in function1
 - Pass that tags lifted statements if they are important
 - English sentence translator
 - Dynamic regenerator for fuzzing
 - Earlier talk about tagging instructions using the LISP

My initial approach has been to first write a "tagging system", which is mostly complete. The idea here is to have a database of system and library calls, some specification of what each one does, and then to scan the program, tagging the use of each call with what it does.

---

Ok so once each call is tagged with the appropriate statements. The next step is to find the dataflow between them. And I'm most of the way done with this step, it's not compelteley working yet but it should be done before I submit my midterm report. Currently what I'm using the binaryninja MLIL (which is a middle level intermediate representation), to track the data flow between each tagged element. There are multiple reasons for the data flow tracking. First, it allows me to replace arguments in statements with actual values. So for example, a call might be tagged that it writes the first the first argument to a file, and data flow might reveal that this argument comes a network recv, so this can be simplified to WRITE(network data, file).

So I've impelemented most of what I've described so far, any questions on that before I get to where I'm hoping to go with it.

Once all analyses above are working, there are several approaches to displaying it in a useful way. The first one I want to try is just a simple graph view, where each statement is a node and the data flow is graphed between them. This could be done at the function level or the global level, depending on how complex the binary is.

An extension of this could be to generate different global models, but let the user specify which side effects it should model. For example, maybe you're wanting to fuzz the binary, so you generate a model just of the file reads. Or maybe you want to look for a backdoor in the binary, so you model just the network reads and command line writes, to see if there might be functionality that allow and attacker to run arbitrary commands over the network.

The second "class" of approaches I'd want to try is writing further analyses that use the high level representation. For example, there are many attempts at using machine learning to detect if some file is malicious. But machine learning on, for example, binary data, is picking out basically things that weakly correlate with it being malicious. What we really want, is to classify some file as malicious/non-malicious directly based on the malicious functionality, like if it runs arbitrary network data as a command. So it would be interesting to try to write a malware classifier based on this.

There are also other things we could do with machine learning. For example, if we generate a long sequence of statements for each function, we might be able to re-use some algorithms from the text summarization literature, to generate a summary for each function.

